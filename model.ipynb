{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95276dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#3.2\n",
    "#Ebenso habe ich auch noch das von google entwickelte Plattform Tensorflow genommen\n",
    "#Das \"Sequential\" im Tensorflow ermöglicht es mir neuronale Netze sequenziell zu stapeln.\n",
    "#Dense ist eine klasse die eine schicht ein neuronales Netzwerk definiert\n",
    "#Dropout ist eine Technik zur Regulierung von neuronalen Netzen\n",
    "#(Der rest folgt dann bei der implementierung)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb78c8a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>TotalVolume</th>\n",
       "      <th>TotalBags</th>\n",
       "      <th>SmallBags</th>\n",
       "      <th>LargeBags</th>\n",
       "      <th>XLargeBags</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18244</th>\n",
       "      <td>1.63</td>\n",
       "      <td>17074.83</td>\n",
       "      <td>13498.67</td>\n",
       "      <td>13066.82</td>\n",
       "      <td>431.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18245</th>\n",
       "      <td>1.71</td>\n",
       "      <td>13888.04</td>\n",
       "      <td>9264.84</td>\n",
       "      <td>8940.04</td>\n",
       "      <td>324.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18246</th>\n",
       "      <td>1.87</td>\n",
       "      <td>13766.76</td>\n",
       "      <td>9394.11</td>\n",
       "      <td>9351.80</td>\n",
       "      <td>42.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18247</th>\n",
       "      <td>1.93</td>\n",
       "      <td>16205.22</td>\n",
       "      <td>10969.54</td>\n",
       "      <td>10919.54</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18248</th>\n",
       "      <td>1.62</td>\n",
       "      <td>17489.58</td>\n",
       "      <td>12014.15</td>\n",
       "      <td>11988.14</td>\n",
       "      <td>26.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>organic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18249 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AveragePrice  TotalVolume  TotalBags  SmallBags  LargeBags  XLargeBags   \n",
       "0              1.33     64236.62    8696.87    8603.62      93.25         0.0  \\\n",
       "1              1.35     54876.98    9505.56    9408.07      97.49         0.0   \n",
       "2              0.93    118220.22    8145.35    8042.21     103.14         0.0   \n",
       "3              1.08     78992.15    5811.16    5677.40     133.76         0.0   \n",
       "4              1.28     51039.60    6183.95    5986.26     197.69         0.0   \n",
       "...             ...          ...        ...        ...        ...         ...   \n",
       "18244          1.63     17074.83   13498.67   13066.82     431.85         0.0   \n",
       "18245          1.71     13888.04    9264.84    8940.04     324.80         0.0   \n",
       "18246          1.87     13766.76    9394.11    9351.80      42.31         0.0   \n",
       "18247          1.93     16205.22   10969.54   10919.54      50.00         0.0   \n",
       "18248          1.62     17489.58   12014.15   11988.14      26.01         0.0   \n",
       "\n",
       "               type  \n",
       "0      conventional  \n",
       "1      conventional  \n",
       "2      conventional  \n",
       "3      conventional  \n",
       "4      conventional  \n",
       "...             ...  \n",
       "18244       organic  \n",
       "18245       organic  \n",
       "18246       organic  \n",
       "18247       organic  \n",
       "18248       organic  \n",
       "\n",
       "[18249 rows x 7 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ich habe mich entschieden das ich für meine Berechnungen die Spalten 'Date', 'Unnamed: 0','4046','4225','4770','year','region nicht brauche\n",
    "#Ebenso wollte ich nicht das er mir eine Kopie gibt sondern es soll direkt verändert werden.\n",
    "df=pd.read_csv(\"avocado.csv\")\n",
    "df.drop(['Date','number','4046','4225','4770','year','region'], axis=1,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "694a5c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier habe ich noch den 'type' zu einer nummer konvertiert\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "type_encoded = one_hot_encoder.fit_transform(df[['type']])\n",
    "type_encoded = pd.DataFrame(type_encoded.toarray(), columns=['conventional','organic'])\n",
    "df_encoded = pd.concat([df, type_encoded], axis=1)\n",
    "df_encoded = df_encoded.drop(['type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "656dd79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>TotalVolume</th>\n",
       "      <th>TotalBags</th>\n",
       "      <th>SmallBags</th>\n",
       "      <th>LargeBags</th>\n",
       "      <th>XLargeBags</th>\n",
       "      <th>conventional</th>\n",
       "      <th>organic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18244</th>\n",
       "      <td>1.63</td>\n",
       "      <td>17074.83</td>\n",
       "      <td>13498.67</td>\n",
       "      <td>13066.82</td>\n",
       "      <td>431.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18245</th>\n",
       "      <td>1.71</td>\n",
       "      <td>13888.04</td>\n",
       "      <td>9264.84</td>\n",
       "      <td>8940.04</td>\n",
       "      <td>324.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18246</th>\n",
       "      <td>1.87</td>\n",
       "      <td>13766.76</td>\n",
       "      <td>9394.11</td>\n",
       "      <td>9351.80</td>\n",
       "      <td>42.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18247</th>\n",
       "      <td>1.93</td>\n",
       "      <td>16205.22</td>\n",
       "      <td>10969.54</td>\n",
       "      <td>10919.54</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18248</th>\n",
       "      <td>1.62</td>\n",
       "      <td>17489.58</td>\n",
       "      <td>12014.15</td>\n",
       "      <td>11988.14</td>\n",
       "      <td>26.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18249 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AveragePrice  TotalVolume  TotalBags  SmallBags  LargeBags  XLargeBags   \n",
       "0              1.33     64236.62    8696.87    8603.62      93.25         0.0  \\\n",
       "1              1.35     54876.98    9505.56    9408.07      97.49         0.0   \n",
       "2              0.93    118220.22    8145.35    8042.21     103.14         0.0   \n",
       "3              1.08     78992.15    5811.16    5677.40     133.76         0.0   \n",
       "4              1.28     51039.60    6183.95    5986.26     197.69         0.0   \n",
       "...             ...          ...        ...        ...        ...         ...   \n",
       "18244          1.63     17074.83   13498.67   13066.82     431.85         0.0   \n",
       "18245          1.71     13888.04    9264.84    8940.04     324.80         0.0   \n",
       "18246          1.87     13766.76    9394.11    9351.80      42.31         0.0   \n",
       "18247          1.93     16205.22   10969.54   10919.54      50.00         0.0   \n",
       "18248          1.62     17489.58   12014.15   11988.14      26.01         0.0   \n",
       "\n",
       "       conventional  organic  \n",
       "0               1.0      0.0  \n",
       "1               1.0      0.0  \n",
       "2               1.0      0.0  \n",
       "3               1.0      0.0  \n",
       "4               1.0      0.0  \n",
       "...             ...      ...  \n",
       "18244           0.0      1.0  \n",
       "18245           0.0      1.0  \n",
       "18246           0.0      1.0  \n",
       "18247           0.0      1.0  \n",
       "18248           0.0      1.0  \n",
       "\n",
       "[18249 rows x 8 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c2b54c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hier habe ich das Datenset in training und testing eingeteilt\n",
    "X = df_encoded.drop(['AveragePrice'], axis=1)\n",
    "y = df_encoded['AveragePrice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#Hier habe ich die numerischen Merkmale der Trainings- und Testdatensätze skaliert mithilfe von StandartScaler\n",
    "numeric_transformer = StandardScaler()\n",
    "numeric_features = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "ct = ColumnTransformer([('numeric', numeric_transformer, numeric_features)], remainder='passthrough')\n",
    "X_train_scaled = ct.fit_transform(X_train)\n",
    "X_test_scaled = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42c90e69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 128)               1024      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,345\n",
      "Trainable params: 9,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Neuronale Netzwerk architektur definieren\n",
    "#Habe habe das Neuronale Netzwerk von Tensorflow genommen, da ich das einfacher finde und mit dem Neuronalen Netzwerk auf sklearn sehr Probleme hatte.\n",
    "#Es hatte viele gute Turtorials dazu und uch habe gehört es besser ist als das von sklearn.\n",
    "#Ebenso war es auch sehr einfach zu implementieren und zu konfigurieren.\n",
    "model = Sequential([\n",
    "    Dense(128, input_shape=(X_train_scaled.shape[1],), activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Kompiliert das Modell und eine Zusammenfassung des Modells\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "440ed20d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "457/457 - 3s - loss: 0.1979 - mae: 0.3239 - 3s/epoch - 6ms/step\n",
      "Epoch 2/50\n",
      "457/457 - 1s - loss: 0.1285 - mae: 0.2744 - 1s/epoch - 3ms/step\n",
      "Epoch 3/50\n",
      "457/457 - 1s - loss: 0.1195 - mae: 0.2653 - 1s/epoch - 3ms/step\n",
      "Epoch 4/50\n",
      "457/457 - 1s - loss: 0.1130 - mae: 0.2585 - 1s/epoch - 2ms/step\n",
      "Epoch 5/50\n",
      "457/457 - 1s - loss: 0.1099 - mae: 0.2549 - 1s/epoch - 2ms/step\n",
      "Epoch 6/50\n",
      "457/457 - 1s - loss: 0.1074 - mae: 0.2515 - 1s/epoch - 3ms/step\n",
      "Epoch 7/50\n",
      "457/457 - 1s - loss: 0.1044 - mae: 0.2475 - 1s/epoch - 3ms/step\n",
      "Epoch 8/50\n",
      "457/457 - 1s - loss: 0.1031 - mae: 0.2458 - 1s/epoch - 2ms/step\n",
      "Epoch 9/50\n",
      "457/457 - 1s - loss: 0.1000 - mae: 0.2417 - 1s/epoch - 3ms/step\n",
      "Epoch 10/50\n",
      "457/457 - 1s - loss: 0.0992 - mae: 0.2415 - 1s/epoch - 3ms/step\n",
      "Epoch 11/50\n",
      "457/457 - 1s - loss: 0.0980 - mae: 0.2396 - 1s/epoch - 2ms/step\n",
      "Epoch 12/50\n",
      "457/457 - 1s - loss: 0.0969 - mae: 0.2374 - 1s/epoch - 3ms/step\n",
      "Epoch 13/50\n",
      "457/457 - 1s - loss: 0.0953 - mae: 0.2348 - 1s/epoch - 2ms/step\n",
      "Epoch 14/50\n",
      "457/457 - 1s - loss: 0.0953 - mae: 0.2355 - 1s/epoch - 2ms/step\n",
      "Epoch 15/50\n",
      "457/457 - 1s - loss: 0.0941 - mae: 0.2335 - 1s/epoch - 2ms/step\n",
      "Epoch 16/50\n",
      "457/457 - 1s - loss: 0.0940 - mae: 0.2338 - 1s/epoch - 3ms/step\n",
      "Epoch 17/50\n",
      "457/457 - 1s - loss: 0.0925 - mae: 0.2318 - 1s/epoch - 3ms/step\n",
      "Epoch 18/50\n",
      "457/457 - 1s - loss: 0.0929 - mae: 0.2320 - 1s/epoch - 3ms/step\n",
      "Epoch 19/50\n",
      "457/457 - 1s - loss: 0.0919 - mae: 0.2304 - 1s/epoch - 2ms/step\n",
      "Epoch 20/50\n",
      "457/457 - 1s - loss: 0.0915 - mae: 0.2302 - 1s/epoch - 3ms/step\n",
      "Epoch 21/50\n",
      "457/457 - 1s - loss: 0.0913 - mae: 0.2296 - 1s/epoch - 2ms/step\n",
      "Epoch 22/50\n",
      "457/457 - 1s - loss: 0.0903 - mae: 0.2284 - 1s/epoch - 2ms/step\n",
      "Epoch 23/50\n",
      "457/457 - 1s - loss: 0.0903 - mae: 0.2284 - 1s/epoch - 2ms/step\n",
      "Epoch 24/50\n",
      "457/457 - 1s - loss: 0.0901 - mae: 0.2280 - 1s/epoch - 2ms/step\n",
      "Epoch 25/50\n",
      "457/457 - 1s - loss: 0.0899 - mae: 0.2284 - 1s/epoch - 2ms/step\n",
      "Epoch 26/50\n",
      "457/457 - 1s - loss: 0.0898 - mae: 0.2280 - 1s/epoch - 2ms/step\n",
      "Epoch 27/50\n",
      "457/457 - 1s - loss: 0.0891 - mae: 0.2272 - 1s/epoch - 2ms/step\n",
      "Epoch 28/50\n",
      "457/457 - 1s - loss: 0.0891 - mae: 0.2266 - 1s/epoch - 2ms/step\n",
      "Epoch 29/50\n",
      "457/457 - 1s - loss: 0.0889 - mae: 0.2264 - 1s/epoch - 2ms/step\n",
      "Epoch 30/50\n",
      "457/457 - 1s - loss: 0.0892 - mae: 0.2271 - 1s/epoch - 2ms/step\n",
      "Epoch 31/50\n",
      "457/457 - 1s - loss: 0.0890 - mae: 0.2267 - 1s/epoch - 2ms/step\n",
      "Epoch 32/50\n",
      "457/457 - 1s - loss: 0.0896 - mae: 0.2270 - 1s/epoch - 3ms/step\n",
      "Epoch 33/50\n",
      "457/457 - 1s - loss: 0.0891 - mae: 0.2271 - 1s/epoch - 3ms/step\n",
      "Epoch 34/50\n",
      "457/457 - 1s - loss: 0.0893 - mae: 0.2271 - 1s/epoch - 3ms/step\n",
      "Epoch 35/50\n",
      "457/457 - 1s - loss: 0.0890 - mae: 0.2266 - 1s/epoch - 2ms/step\n",
      "Epoch 36/50\n",
      "457/457 - 1s - loss: 0.0893 - mae: 0.2269 - 1s/epoch - 2ms/step\n",
      "Epoch 37/50\n",
      "457/457 - 1s - loss: 0.0887 - mae: 0.2262 - 1s/epoch - 2ms/step\n",
      "Epoch 38/50\n",
      "457/457 - 1s - loss: 0.0895 - mae: 0.2272 - 1s/epoch - 3ms/step\n",
      "Epoch 39/50\n",
      "457/457 - 1s - loss: 0.0885 - mae: 0.2257 - 1s/epoch - 3ms/step\n",
      "Epoch 40/50\n",
      "457/457 - 1s - loss: 0.0892 - mae: 0.2269 - 1s/epoch - 3ms/step\n",
      "Epoch 41/50\n",
      "457/457 - 1s - loss: 0.0889 - mae: 0.2262 - 1s/epoch - 3ms/step\n",
      "Epoch 42/50\n",
      "457/457 - 1s - loss: 0.0885 - mae: 0.2259 - 1s/epoch - 2ms/step\n",
      "Epoch 43/50\n",
      "457/457 - 1s - loss: 0.0888 - mae: 0.2266 - 1s/epoch - 3ms/step\n",
      "Epoch 44/50\n",
      "457/457 - 1s - loss: 0.0880 - mae: 0.2252 - 1s/epoch - 3ms/step\n",
      "Epoch 45/50\n",
      "457/457 - 1s - loss: 0.0880 - mae: 0.2249 - 1s/epoch - 3ms/step\n",
      "Epoch 46/50\n",
      "457/457 - 1s - loss: 0.0884 - mae: 0.2259 - 1s/epoch - 3ms/step\n",
      "Epoch 47/50\n",
      "457/457 - 1s - loss: 0.0877 - mae: 0.2251 - 1s/epoch - 2ms/step\n",
      "Epoch 48/50\n",
      "457/457 - 1s - loss: 0.0882 - mae: 0.2254 - 1s/epoch - 2ms/step\n",
      "Epoch 49/50\n",
      "457/457 - 1s - loss: 0.0881 - mae: 0.2250 - 1s/epoch - 2ms/step\n",
      "Epoch 50/50\n",
      "457/457 - 1s - loss: 0.0885 - mae: 0.2255 - 1s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#Das Model Trainieren\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ceba266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0881 - mae: 0.2251 - val_loss: 0.0880 - val_mae: 0.2251\n",
      "Epoch 2/50\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.0883 - mae: 0.2247 - val_loss: 0.0881 - val_mae: 0.2281\n",
      "Epoch 3/50\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.0877 - mae: 0.2241 - val_loss: 0.0888 - val_mae: 0.2286\n",
      "Epoch 4/50\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0878 - mae: 0.2245 - val_loss: 0.0879 - val_mae: 0.2270\n",
      "Epoch 5/50\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.0876 - mae: 0.2247 - val_loss: 0.0885 - val_mae: 0.2263\n",
      "Epoch 6/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0868 - mae: 0.2230 - val_loss: 0.0879 - val_mae: 0.2266\n",
      "Epoch 7/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0878 - mae: 0.2244 - val_loss: 0.0882 - val_mae: 0.2281\n",
      "Epoch 8/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0877 - mae: 0.2244 - val_loss: 0.0899 - val_mae: 0.2284\n",
      "Epoch 9/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0873 - mae: 0.2240 - val_loss: 0.0886 - val_mae: 0.2287\n",
      "Epoch 10/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0875 - mae: 0.2250 - val_loss: 0.0907 - val_mae: 0.2314\n",
      "Epoch 11/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0869 - mae: 0.2236 - val_loss: 0.0880 - val_mae: 0.2270\n",
      "Epoch 12/50\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.0866 - mae: 0.2229 - val_loss: 0.0873 - val_mae: 0.2250\n",
      "Epoch 13/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0872 - mae: 0.2238 - val_loss: 0.0885 - val_mae: 0.2283\n",
      "Epoch 14/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0878 - mae: 0.2244 - val_loss: 0.0868 - val_mae: 0.2250\n",
      "Epoch 15/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0866 - mae: 0.2233 - val_loss: 0.0878 - val_mae: 0.2280\n",
      "Epoch 16/50\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.0869 - mae: 0.2238 - val_loss: 0.0883 - val_mae: 0.2298\n",
      "Epoch 17/50\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.0863 - mae: 0.2234 - val_loss: 0.0907 - val_mae: 0.2321\n",
      "Epoch 18/50\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0865 - mae: 0.2230 - val_loss: 0.0881 - val_mae: 0.2252\n",
      "Epoch 19/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0869 - mae: 0.2238 - val_loss: 0.0877 - val_mae: 0.2276\n",
      "Epoch 20/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0863 - mae: 0.2231 - val_loss: 0.0871 - val_mae: 0.2253\n",
      "Epoch 21/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0867 - mae: 0.2233 - val_loss: 0.0886 - val_mae: 0.2293\n",
      "Epoch 22/50\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.0864 - mae: 0.2228 - val_loss: 0.0894 - val_mae: 0.2246\n",
      "Epoch 23/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0870 - mae: 0.2233 - val_loss: 0.0872 - val_mae: 0.2265\n",
      "Epoch 24/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0869 - mae: 0.2233 - val_loss: 0.0876 - val_mae: 0.2250\n",
      "Epoch 25/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0867 - mae: 0.2230 - val_loss: 0.0874 - val_mae: 0.2262\n",
      "Epoch 26/50\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.0872 - mae: 0.2236 - val_loss: 0.0875 - val_mae: 0.2249\n",
      "Epoch 27/50\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0869 - mae: 0.2235 - val_loss: 0.0886 - val_mae: 0.2246\n",
      "Epoch 28/50\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.0865 - mae: 0.2227 - val_loss: 0.0873 - val_mae: 0.2267\n",
      "Epoch 29/50\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0861 - mae: 0.2227 - val_loss: 0.0879 - val_mae: 0.2276\n",
      "Epoch 30/50\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.0862 - mae: 0.2225 - val_loss: 0.0862 - val_mae: 0.2246\n",
      "Epoch 31/50\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.0860 - mae: 0.2224 - val_loss: 0.0881 - val_mae: 0.2245\n",
      "Epoch 32/50\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0861 - mae: 0.2225 - val_loss: 0.0870 - val_mae: 0.2240\n",
      "Epoch 33/50\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.0866 - mae: 0.2231 - val_loss: 0.0864 - val_mae: 0.2245\n",
      "Epoch 34/50\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.0860 - mae: 0.2221 - val_loss: 0.0852 - val_mae: 0.2209\n",
      "Epoch 35/50\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0853 - mae: 0.2208 - val_loss: 0.0882 - val_mae: 0.2288\n",
      "Epoch 36/50\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0858 - mae: 0.2219 - val_loss: 0.0857 - val_mae: 0.2224\n",
      "Epoch 37/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0857 - mae: 0.2224 - val_loss: 0.0884 - val_mae: 0.2235\n",
      "Epoch 38/50\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.0855 - mae: 0.2212 - val_loss: 0.0870 - val_mae: 0.2276\n",
      "Epoch 39/50\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.0858 - mae: 0.2222 - val_loss: 0.0860 - val_mae: 0.2239\n",
      "Epoch 40/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0855 - mae: 0.2215 - val_loss: 0.0871 - val_mae: 0.2275\n",
      "Epoch 41/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0860 - mae: 0.2222 - val_loss: 0.0870 - val_mae: 0.2271\n",
      "Epoch 42/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0850 - mae: 0.2212 - val_loss: 0.0857 - val_mae: 0.2245\n",
      "Epoch 43/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0848 - mae: 0.2210 - val_loss: 0.0859 - val_mae: 0.2247\n",
      "Epoch 44/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0853 - mae: 0.2216 - val_loss: 0.0875 - val_mae: 0.2276\n",
      "Epoch 45/50\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.0853 - mae: 0.2213 - val_loss: 0.0874 - val_mae: 0.2275\n",
      "Epoch 46/50\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.0850 - mae: 0.2209 - val_loss: 0.0867 - val_mae: 0.2262\n",
      "Epoch 47/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0855 - mae: 0.2215 - val_loss: 0.0856 - val_mae: 0.2237\n",
      "Epoch 48/50\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.0847 - mae: 0.2202 - val_loss: 0.0866 - val_mae: 0.2250\n",
      "Epoch 49/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0850 - mae: 0.2205 - val_loss: 0.0854 - val_mae: 0.2221\n",
      "Epoch 50/50\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.0854 - mae: 0.2215 - val_loss: 0.0859 - val_mae: 0.2245\n"
     ]
    }
   ],
   "source": [
    "# Das Model mit \"X_test_scaled\" und \"y_test\" trainieren\n",
    "history = model.fit(X_train_scaled, y_train, validation_data=(X_test_scaled, y_test), epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec1a186f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 0s 2ms/step\n",
      "[[1.1817518]\n",
      " [1.1749743]\n",
      " [1.755512 ]\n",
      " [1.2138189]\n",
      " [1.7375143]\n",
      " [1.7296013]\n",
      " [1.7983912]\n",
      " [1.0633618]\n",
      " [1.7339671]\n",
      " [1.1941186]]\n",
      "MSE: 0.08594827758297875\n",
      "MAE: 0.22445521709690355\n"
     ]
    }
   ],
   "source": [
    "#3.3\n",
    "#Modell auf dem Testdatensatz evaluiren\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test.to_numpy().reshape(-1), y_pred.reshape(-1))\n",
    "mae = np.mean(np.abs(y_pred.reshape(-1) - y_test.to_numpy().reshape(-1)))\n",
    "\n",
    "print(y_pred[:10])\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "#Die Ergebnisse zeigen, dass das Modell bei der Vorhersage der Testdaten eine relativ geringe mittlere quadratische Abweichung (MSE) von 0,085 aufweist,\n",
    "#was darauf hinweist, dass es eine gute Genauigkeit aufweist.\n",
    "#Ebenso zeigt das mittlere absolute Fehler (MAE) Ergebnis von 0,221, dass die Vorhersage des Modells im Durchschnitt um 0,221 Einheiten vom tatsächlichen Wert abweicht.\n",
    "#Insgesamt scheint das Modell bei der Vorhersage der Testdaten gut abzuschneiden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
